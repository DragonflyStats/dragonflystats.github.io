Model Fit Diagnostics
======================

- Nagelkerke R-Squared


One question that obviously arises when we are looking at regression models is that of the overall fit of the model. As in ordinary linear regression, we can find measures of model fit of logistic regression models.

There are, in fact, a number of different measures of goodness of fit for logistic regression models. The first, most straightforward measure, is to simply look at the extent to which the model accurately predicts the dependent variable, or, in other words, how accurate the model is at predicting whether or not a pupil, in this sample, is likely to report having literature in their home. This is calculated by comparing the predicted score of the individual students (as either possessing or not possessing literature) on the basis of the two independent variables we have in our model (gender and mother’s education), with their actual group membership as given by the data (in other words, what the data tells us about whether students have actually said they possess or don’t possess literature in the home). 

Hosmer-Lemeshow Test
 One of these measures is the Hosmer-Lemeshow test of goodness of fit. This is similar to a Chi Square test, and indicates the extent to which the model provides better fit than a null model with no predictors, or, in a different interpretation, how well the model fits the data, as in log-linear modelling. If chi-square goodness of fit is not significant, then the model has adequate fit. By the same token, if the test is significant, the model does not adequately fit the data. The Hosmer and Lemeshow's (H-L) goodness of fit test divides subjects into deciles based on predicted probabilities, then computes a chi-square from observed and expected frequencies. Then a probability (p) value is computed from the chi-square distribution to test the fit of the logistic model. If the H-L goodness-of-fit test statistic is greater than .05, as we want for well-fitting models, we fail to reject the null hypothesis that there is no difference between observed and model-predicted values, implying that the model's estimates fit the data at an acceptable level. That is, well-fitting models show nonsignificance on the goodness-of-fit test, indicating model prediction that is not significantly different from observed values.

A disadvantage of this goodness of fit measure is that it is a significance test, with all the limitations this entails. Like other significant tests it only tells us whether the model fits or not, and does not tell us anything about the extent of the fit. Similarly, like other significance tests, it is strongly influenced by the sample size (sample size and effect size both determine significance), and in large samples, such as the PISA dataset we are using here, a very small difference will lead to significance. As the sample size gets large, the H-L statistic can find smaller and smaller differences between observed and model-predicted values to be significant. Small sample sizes are also problematic, however, as, being a Chi Square test we can’t have too many groups (more than 10%) with predicted frequencies of less than five.

The Hosmer-Lemeshow test of goodness of fit is not automatically a part of the SPSS logistic regression output. To get this output, we need to go into ‘options’ and tick the box marked Hosmer-Lemeshow test of goodness of fit. In our example, this gives us the following output:

 Step	 Chi-square	df 	 Sig.
 1	 142.032	 6	 .000
Therefore, our model is significant, suggesting it does not fit the data. However, as we have a sample size of over 13,000, even very small divergencies of the model from the data would be flagged up and cause significance. Therefore, with samples of this size it is hard to find models that are parsimonious (i.e. that use the minimum amount of independent variables to explain the dependent variable) and fit the data. Therefore, other fit indices might be more appropriate.

 In ordinary linear regression, our primary measure of model fit was R2, which was an indicator of the percentage of variance in the dependent variable explained by the model. It would be useful for us to have a similar measure for logistic regression. However, the R2 measure is only appropriate to linear regression, with its continuous dependent variables. To get around this problem, a number of statisticians have developed so-called ‘Pseudo R2 ’ measures that aim to mimic R2 for logistic regression models. In contrast to the actual R2 , as these are approximations there are a number of different Pseudo R Squares, which take a different conceptual approach to what R2 means .

The most commonly used interpret R2 as representing the improvement of the model we are using (in our case the two variable model) over the null model with no independent variables (also called predictors). Other approaches are based on viewing R2 as explained variance.

In the first category we can find two Pseudo R2   measures used in SPSS, Cox and Snell’s and Nagelkerke’s Pseudo R square measures. Cox and Snell's R2 is based on calculating the proportion of unexplained variance that is reduced by adding variables to the model.

The formula for Cox and Snell's Pseudo R2 is:

where -2LLnull is the loglikelihood for the empty model, and -2LLk is the loglikelihood for the model with the independent variables.

There is a major problem with Cox and Snell’s Pseudo R Square, however, which is that its maximum can be (and usually is) less than 1.0, making it difficult to interpret. That is why Nagelkerke developed a modified version of Cox and Snell’s measure that varies from 0 to 1. To achieve this, Nagelkerke's R 2 divides Cox and Snell's R 2 by its maximum, giving us the formula:

Therefore Nagelkerke's Pseudo R2 will normally be higher than the Cox and Snell measure. Both of these Pseudo R2 measures will tend to be lower than traditional ordinary least squares R2 measures.


<hr>
### Effron's Pseudo R-squared
An example of an approach that views R2 as explained variance is Effron’s Pseudo R2. This measure takes the model residuals, which are squared, summed, and divided by the total variability in the dependent variable:


This R-squared is equal to the squared correlation between the predicted values and actual values. 

Other Pseudo R2s, such as Mc Fadden’s and McKelvey and Zavoina’s measures also exist, but we will not discuss them all in detail here. However, the existence of multiple measures, as opposed to the one R2 we had in ordinary linear regression points to the facts that these are approximations of R2, which are inexact and disputable to some extent, and it is important to remember that they will give us somewhat different numbers.

<hr>



### Pseudo R-Squared in SPSS
In SPSS we only get two Pseudo R2 measures in the output, Cox and Snell and Nagelkerke. These are given in the box labelled ‘model summary’ in the output:

Step

-2 Log likelihood

Cox & Snell R Square

Nagelkerke R Square

1

16327.952(a)

.055

.074

As we can see, Nagelkerke’s measure gives us a higher value than does Cox and Snell’s as we would expect. We also said earlier that Nagelkerke’s measure was a correction of Cox and Snell’s, allowing the measure to use the full 0-1 range, so we will prefer to use this one.

Whichever of the measures we use, however, we can see that fit of the model is poor. As .07 is close to 0 our model is not a great improvement over the null model with no predictors.

Summarising what these three measures tell us about the fit of our model, the Hosmer and Lemesnow Goodness of Fit Chi Square test indicates that our model does not fit the data. However, this measure is sensitive to sample size, and in our large sample few parsimonious models would fit. Nevertheless, poor fit is also indicated by the other measures. Accuracy of prediction has improved over the null model, but only by 4%. Nagelkerke’s Pseudo R2 is only .07, again (think of an analogous R2in ordinary linear regression) indicating poor fit. So, even though both our predictors are significant, they are weak predictors of possessing literature in the home.

### References
- http://www.statisticalhorizons.com/r2logistic



Evaluating goodness of fit[edit]
Discrimination in linear regression models is generally measured using R2. Since this has no direct analog in logistic regression, various methods[24]:ch.21 including the following can be used instead.

Deviance and likelihood ratio tests[edit]
In linear regression analysis, one is concerned with partitioning variance via the sum of squares calculations – variance in the criterion is essentially divided into variance accounted for by the predictors and residual variance. In logistic regression analysis, deviance is used in lieu of sum of squares calculations.[25] Deviance is analogous to the sum of squares calculations in linear regression[17] and is a measure of the lack of fit to the data in a logistic regression model.[25] When a "saturated" model is available (a model with a theoretically perfect fit), deviance is calculated by comparing a given model with the saturated model.[17] This computation gives the likelihood-ratio test:[17]

{\displaystyle D=-2\ln {\frac {\text{likelihood of the fitted model}}{\text{likelihood of the saturated model}}}.} D=-2\ln {\frac {\text{likelihood of the fitted model}}{\text{likelihood of the saturated model}}}.
In the above equation D represents the deviance and ln represents the natural logarithm. The log of this likelihood ratio (the ratio of the fitted model to the saturated model) will produce a negative value, hence the need for a negative sign. D can be shown to follow an approximate chi-squared distribution.[17] Smaller values indicate better fit as the fitted model deviates less from the saturated model. When assessed upon a chi-square distribution, nonsignificant chi-square values indicate very little unexplained variance and thus, good model fit. Conversely, a significant chi-square value indicates that a significant amount of the variance is unexplained.

When the saturated model is not available (a common case), deviance is calculated simply as −2·(log likelihood of the fitted model), and the reference to the saturated model's log likelihood can be removed from all that follows without harm.

Two measures of deviance are particularly important in logistic regression: null deviance and model deviance. The null deviance represents the difference between a model with only the intercept (which means "no predictors") and the saturated model. The model deviance represents the difference between a model with at least one predictor and the saturated model.[25] In this respect, the null model provides a baseline upon which to compare predictor models. Given that deviance is a measure of the difference between a given model and the saturated model, smaller values indicate better fit. Thus, to assess the contribution of a predictor or set of predictors, one can subtract the model deviance from the null deviance and assess the difference on a {\displaystyle \chi _{s-p}^{2},} \chi _{s-p}^{2}, chi-square distribution with degrees of freedom[17] equal to the difference in the number of parameters estimated.

Let

{\displaystyle {\begin{aligned}D_{\text{null}}&=-2\ln {\frac {\text{likelihood of null model}}{\text{likelihood of the saturated model}}}\\[6pt]\ D_{\text{fitted}}&=-2\ln {\frac {\text{likelihood of fitted model}}{\text{likelihood of the saturated model}}}.\end{aligned}}} {\displaystyle {\begin{aligned}D_{\text{null}}&=-2\ln {\frac {\text{likelihood of null model}}{\text{likelihood of the saturated model}}}\\[6pt]\ D_{\text{fitted}}&=-2\ln {\frac {\text{likelihood of fitted model}}{\text{likelihood of the saturated model}}}.\end{aligned}}}
Then the difference of both is:

{\displaystyle {\begin{aligned}&D_{\text{null}}-D_{\text{fitted}}\\[6pt]={}&-2\left(\ln {\frac {\text{likelihood of null model}}{\text{likelihood of the saturated model}}}-\ln {\frac {\text{likelihood of fitted model}}{\text{likelihood of the saturated model}}}\right)\\[6pt]={}&-2\ln {\frac {\left({\dfrac {\text{likelihood of null model}}{\text{likelihood of the saturated model}}}\right)}{\left({\dfrac {\text{likelihood of fitted model}}{\text{likelihood of the saturated model}}}\right)}}\\[6pt]={}&-2\ln {\frac {\text{likelihood of the null model}}{\text{likelihood of fitted model}}}.\end{aligned}}} {\displaystyle {\begin{aligned}&D_{\text{null}}-D_{\text{fitted}}\\[6pt]={}&-2\left(\ln {\frac {\text{likelihood of null model}}{\text{likelihood of the saturated model}}}-\ln {\frac {\text{likelihood of fitted model}}{\text{likelihood of the saturated model}}}\right)\\[6pt]={}&-2\ln {\frac {\left({\dfrac {\text{likelihood of null model}}{\text{likelihood of the saturated model}}}\right)}{\left({\dfrac {\text{likelihood of fitted model}}{\text{likelihood of the saturated model}}}\right)}}\\[6pt]={}&-2\ln {\frac {\text{likelihood of the null model}}{\text{likelihood of fitted model}}}.\end{aligned}}}
If the model deviance is significantly smaller than the null deviance then one can conclude that the predictor or set of predictors significantly improved model fit. This is analogous to the F-test used in linear regression analysis to assess the significance of prediction.[25]

Pseudo-R2s[edit]
In linear regression the squared multiple correlation, R2 is used to assess goodness of fit as it represents the proportion of variance in the criterion that is explained by the predictors.[25] In logistic regression analysis, there is no agreed upon analogous measure, but there are several competing measures each with limitations.[25][26]

Four of the most commonly used indices and one less commonly used one are examined on this page:

Likelihood ratio R2L
Cox and Snell R2CS
Nagelkerke R2N
McFadden R2McF
Tjur R2T
R2L is given by [25]

{\displaystyle R_{\text{L}}^{2}={\frac {D_{\text{null}}-D_{\text{fitted}}}{D_{\text{null}}}}.} R_{\text{L}}^{2}={\frac {D_{\text{null}}-D_{\text{fitted}}}{D_{\text{null}}}}.
This is the most analogous index to the squared multiple correlation in linear regression.[20] It represents the proportional reduction in the deviance wherein the deviance is treated as a measure of variation analogous but not identical to the variance in linear regression analysis.[20] One limitation of the likelihood ratio R2 is that it is not monotonically related to the odds ratio,[25] meaning that it does not necessarily increase as the odds ratio increases and does not necessarily decrease as the odds ratio decreases.

R2CS is an alternative index of goodness of fit related to the R2 value from linear regression.[26] It is given by:

{\displaystyle R_{\text{CS}}^{2}=1-\left({\frac {L_{M}}{L_{0}}}\right)^{2/n}.} {\displaystyle R_{\text{CS}}^{2}=1-\left({\frac {L_{M}}{L_{0}}}\right)^{2/n}.}
where LM and L0 are the likelihoods for the model being fitted and the null model, respectively. The Cox and Snell index is problematic as its maximum value is {\displaystyle 1-L_{0}^{2/n}} 1-L_{0}^{2/n}. The highest this upper bound can be is 0.75, but it can easily be as low as 0.48 when the marginal proportion of cases is small.[26]

R2N provides a correction to the Cox and Snell R2 so that the maximum value is equal to 1. Nevertheless, the Cox and Snell and likelihood ratio R2s show greater agreement with each other than either does with the Nagelkerke R2.[25] Of course, this might not be the case for values exceeding .75 as the Cox and Snell index is capped at this value. The likelihood ratio R2 is often preferred to the alternatives as it is most analogous to R2 in linear regression, is independent of the base rate (both Cox and Snell and Nagelkerke R2s increase as the proportion of cases increase from 0 to .5) and varies between 0 and 1.

R2McF is defined as

{\displaystyle R_{\text{McF}}^{2}=1-{\frac {\ln(L_{M})}{\ln(L_{0})}},} {\displaystyle R_{\text{McF}}^{2}=1-{\frac {\ln(L_{M})}{\ln(L_{0})}},}
and is preferred over R2CS by Allison.[26] The two expressions R2McF and R2CS are then related respectively by,

{\displaystyle {\begin{matrix}R_{\text{CS}}^{2}=1-\left({\dfrac {1}{L_{0}}}\right)^{\frac {2(R_{\text{McF}}^{2})}{n}}\\[1.5em]R_{\text{McF}}^{2}=-{\dfrac {n}{2}}\cdot {\dfrac {\ln(1-R_{\text{CS}}^{2})}{\ln(L_{0})}}\end{matrix}}} {\begin{matrix}R_{\text{CS}}^{2}=1-\left({\dfrac {1}{L_{0}}}\right)^{\frac {2(R_{\text{McF}}^{2})}{n}}\\[1.5em]R_{\text{McF}}^{2}=-{\dfrac {n}{2}}\cdot {\dfrac {\ln(1-R_{\text{CS}}^{2})}{\ln(L_{0})}}\end{matrix}}
However, Allison now prefers R2T which is a relatively new measure developed by Tjur.[27] It can be calculated in two steps:[26]

For each level of the dependent variable, find the mean of the predicted probabilities of an event.
Take the absolute value of the difference between these means
A word of caution is in order when interpreting pseudo-R2 statistics. The reason these indices of fit are referred to as pseudo R2 is that they do not represent the proportionate reduction in error as the R2 in linear regression does.[25] Linear regression assumes homoscedasticity, that the error variance is the same for all values of the criterion. Logistic regression will always be heteroscedastic – the error variances differ for each value of the predicted score. For each value of the predicted score there would be a different value of the proportionate reduction in error. Therefore, it is inappropriate to think of R2 as a proportionate reduction in error in a universal sense in logistic regression.[25]


