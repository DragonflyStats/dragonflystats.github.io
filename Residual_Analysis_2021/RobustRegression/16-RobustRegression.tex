\documentclass[residuals.tex]{subfiles}

% Load any packages needed for this document
\begin{document}
%-------------------------------------------------------------- %
\newpage
\Large
\section{Robust Regression}

Robust regression is an alternative to ordinary least squares regression (OLS , the type of regression we have discussed thus far) when data is contaminated with outliers or influential observations and it can also be used for the purpose of detecting influential observations.


%This will produce a set of four plots: residuals versus fitted values, a Q-Q plot of standardized residuals, a scale-location plot (square roots of standardized residuals versus fitted values, and a plot of residuals versus leverage that adds bands corresponding to Cook's distances of 0.5 and 1. 
%
%Using the plot to get a detailed interpretation of how well the model fits is beyond the scope of this module. However it is worth noting that plots identify particular observations that may warrant re-examination. 
%
%\textbf{Remarks :} 
%% OLD MA4605 Notes
%The plots actually indicate the fitted model is actually quite good. The trend lines in the first and third plots demonstrate constant variance, and in the case of the first, the trend line through the centre of the plot  follows the X=0 line quite well.
%
%The Q-Q plot (i.e. the second plot) indicates that the assumption of normality is vindicated.
%The last plot indicates the no observations have unusually high Cook’s Distances values.  No observations are beyond the 0.5 (red line) threshold.
%
%Robust regression is an alternative to least squares regression when data are contaminated with outliers or influential observations, and it can also be used for the purpose of detecting influential observation
%
%% IMAGES HERE

%Additionally I have added a line plot of the Cook’s Distance values. Which observations have the highest values for Cook’s Distance?

\newpage
%------------------------------------------------------------------------------------%
\subsection{The Cheese data set}

\begin{framed}
\begin{verbatim}
FitAll = lm(Taste ~ Acetic + H2S + Lactic)
plot(FitAll)
\end{verbatim}
\end{framed}


%------------------------------------------------------------------------------------%
\subsection{The stackloss data set}
%Used in "rlm" help file
Brownlee's Stack Loss Plant Data contains operational data of a plant for the oxidation of ammonia to nitric acid.

The variables are: 
\begin{itemize}
\item	Air.Flow	 Flow of cooling air
\item	Water.Temp	 Cooling Water Inlet Temperature
\item	Acid.Conc.	 Concentration of acid [per 1000, minus 500]
\item	stack.loss	 Stack loss
\end{itemize}

\begin{framed}
\begin{verbatim}
fit.sl = lm(stack.loss ~ ., data = stackloss)

attach(stackloss)
plot(Acid.Conc. , stack.loss, pch = 18, col="red")

plot(fit.sl)
\end{verbatim}
\end{framed}
%-------------------------------------%
\newpage


\subsection*{Robust Regression }
% - (Wikipedia)
\begin{itemize}
\item In robust statistics, robust regression is a form of regression analysis designed to circumvent some 
limitations of traditional parametric and non-parametric methods. Regression analysis seeks to find the 
relationship between one or more independent variables and a dependent variable. 
\item Certain widely used methods of regression, such as ordinary least squares, have favourable properties if their
underlying assumptions are true, but can give misleading results if those assumptions are not true; thus
ordinary least squares is said to be not robust to violations of its assumptions. Robust regression methods are designed to be not overly affected by violations of assumptions by the underlying data-generating process.
\end{itemize}
\newpage
\subsubsection*{Usage of Robust Regression}
\begin{itemize}
\item Robust regression can be used in any situation in which you would use least squares regression. 
When fitting a least squares regression, we might find some outliers or high leverage data points.
\item We have decided that these data points are not data entry errors, neither they are from a different population 
than most of our data. So we have no compelling reason to exclude them from the analysis. 
\item Robust regression might be a good strategy since it is a compromise between excluding these points entirely from the analysis and including all the data points and treating all them equally in OLS regression. The idea of robust regression is to weigh the observations differently based on how well behaved these observations are. Roughly speaking, it is a form of weighted and reweighted least squares regression.
\item Robust regression does not address issues of heterogeneity of variance. 
\end{itemize}
\newpage
\subsubsection*{Popularity of Robust Regression}
Despite their superior performance over least squares estimation in many situations, robust methods for regression are still not widely used. Several reasons may help explain their unpopularity (Hampel et al. 1986, 2005). One possible reason is that there are several competing methods and the field got off to many false starts. Also, computation of robust estimates is much more computationally intensive than least squares estimation; in recent years however, this objection has become less relevant as computing power has increased greatly. Another reason may be that some popular statistical software packages failed to implement the methods (Stromberg, 2004). The belief of many statisticians that classical methods are robust may be another reason.

\subsection{Fitting a robust model (\texttt{rlm}}
The rlm command in the MASS package command implements several versions of robust regression. 
%-------------------------------------%
\begin{framed}
\begin{verbatim}
summary(rlm(stack.loss ~ ., data = stackloss))
\end{verbatim}
\end{framed}
%-------------------------------------%
\begin{verbatim}
> summary(rlm(stack.loss ~ ., stackloss))

Call: rlm(formula = stack.loss ~ ., data = stackloss)
Residuals:
     Min       1Q   Median       3Q      Max 
-8.91753 -1.73127  0.06187  1.54306  6.50163 

Coefficients:
            Value    Std. Error t value 
(Intercept) -41.0265   9.8073    -4.1832
Air.Flow      0.8294   0.1112     7.4597
Water.Temp    0.9261   0.3034     3.0524
Acid.Conc.   -0.1278   0.1289    -0.9922

Residual standard error: 2.441 on 17 degrees of freedom
\end{verbatim}
\newpage
%-------------------------------------%
\begin{framed}
\begin{verbatim}
 rlm(stack.loss ~ ., stackloss, psi = psi.hampel, init = "lts")
\end{verbatim}
\end{framed}
%-------------------------------------%
\begin{verbatim}
> rlm(stack.loss ~ ., stackloss, psi = psi.hampel, init = "lts")
Call:
rlm(formula = stack.loss ~ ., data = stackloss, psi = psi.hampel, 
    init = "lts")
Converged in 10 iterations

Coefficients:
(Intercept)    Air.Flow  Water.Temp  Acid.Conc. 
-40.4748037   0.7410863   1.2250703  -0.1455242 

Degrees of freedom: 21 total; 17 residual
Scale estimate: 3.09 
\end{verbatim}
\newpage
%-------------------------------------%
\subsection{Using Other \textit{Psi} Operators}

\begin{itemize}
\item huber
\item bisquare
\item hampel
\end{itemize}
Fitting is done by \textbf{\emph{iterated re-weighted least squares (IWLS).}}

Psi functions are supplied for the Huber, Hampel and Tukey bisquare proposals as \texttt{psi.huber}, \texttt{psi.hampel} and \texttt{psi.bisquare}. Huber's corresponds to a convex optimization problem and gives a unique solution (up to collinearity). The other two will have multiple local minima, and a good starting point is desirable.





\begin{framed}
\begin{verbatim}
 rlm(stack.loss ~ ., stackloss, psi = psi.bisquare)
\end{verbatim}
\end{framed}
\begin{verbatim}
Call:
rlm(formula = stack.loss ~ ., data = stackloss, psi = psi.bisquare)
Converged in 11 iterations

Coefficients:
(Intercept)    Air.Flow  Water.Temp  Acid.Conc. 
-42.2852537   0.9275471   0.6507322  -0.1123310 

Degrees of freedom: 21 total; 17 residual
Scale estimate: 2.28 
\end{verbatim}

\newpage
\subsection{Implementation of Robust Regression}
\begin{itemize}
\item When fitting a least squares regression, we might find some outliers or high leverage data points.  We have decided that these data points are not data entry errors, neither they are from a different population than most of our data. So we have no proper reason to exclude them from the analysis.  

\item Robust regression might be a good strategy since it is a compromise between excluding these points entirely from the analysis and including all the data points and treating all them equally in OLS regression. The idea of robust regression is to weigh the observations differently based on how well behaved these observations are.

\item 
The idea of robust regression is to weigh the observations differently based on how well behaved these observations are. Roughly speaking, it is a form of weighted and reweighted least squares regression (i.e. a two step process , first fitting a linear model, then a robust model to correct for the influence of outliers).
\item 
Robust regression is done by iterated re-weighted least squares (IRLS). The rlm command in the MASS package command implements several versions of robust regression.
